# model
source: "hf" # raw, hf
protocol: "s3" # file, s3
model_path: "hdd:s3://opennlplab_hdd/models/llama/llama-7b-hf"
tokenizer_path: "./tokenizer.model"
pp_size: 6
dp_size: 1
micro_batch_num: 10
fp16: True
checkpoint: True
dense: "raw" # raw, fused, apex
attention: "raw" # raw, flash, col_flash, mem_eff
rotary_emb: "raw" # raw, fused
rms_norm: "raw" # raw, apex
# data
dataset_name: 'openbookqa'
refresh: false
data_tag: 'src'
max_length: 256
few_shot_size: -1
# tunelite
# trainer
learning_rate: 0.001
epochs: 10
warmup: 300
eval_per_steps: 100
eval_per_epoches: 1
eval_max_length: 128
# eval_stop_tokens: [2]
eval_top_p: 0.95
eval_temperature: 0.8
# eval_use_cache: True